# 第三周课程总结

第三周的课程明显难了很多，涉及到很多递归、回溯以及剪枝的知识，不是很容易理解。

由于涉及到了树的各种递归操作，对于时间复杂度和空间复杂度的分析上出现了一些模糊的地方。
比如对于链表的归并操作，我的理解也是先操作左子链表，再操作右子链表，再合并。左右子链表操作平均时间复杂度是O(logn)，
合并时间复杂度为O(n)，所以整体的时间复杂度为O(nlogn)。也就是说单纯看一个较为平衡的链表的递归操作的话，时间复杂度是O(logn);
类比到树的遍历，也是先遍历左树，再遍历右树，但是这个时候由于各个节点都至少会遍历一次，不管怎样时间复杂度都是O(n)，
这个时候就无法和链表对应起来了。二者都是类似于二叉树的递归操作，为啥时间复杂度不一致呢？这里的理解是在什么地方出了错？

组合问题的回溯操作的时间复杂度也有点难以理解，没有明白官方题解的时间复杂度是怎么计算的。如果是O(n*k*k)的话，感觉复杂度也太高了。
经过研究，不考虑剪枝的话，关于时间复杂度稍微得到了一点规律：
1. 如果是递归套两次递归，类似于使用"选择或者不选"的思路解组合问题，则时间复杂度为 1+2+4+8+...+2^k = 2^(k+1)-1 = O(n^k);
2. 如果是递归套循环，则时间复杂度为 n*(n-1)*(n-2)*...*(n-k+1) ~ n!

全排列的问题直接参考官方代码，关于first位置的处理比较巧妙，整个回溯过程比较简洁，典型的递归套循环，适合背诵：
fn backtrack_permute2(res: &mut Vec<Vec<i32>>, nums: &mut Vec<i32>, depth: usize, visit: &mut Vec<bool>, path: &mut Vec<i32>) {
    if depth == nums.len() {
        res.push(path.to_vec());
        return;
    }

    for i in 0..nums.len() {
        if visit[i] {
            continue;
        }

        // 动态维护数组
        path.push(nums[i]);
        visit[i] = true;
        // 继续递归填下一个数
        Solution::backtrack_permute2(res, nums, depth + 1, visit, path);
        // 撤销操作
        path.pop();
        visit[i] = false;
    }
}
